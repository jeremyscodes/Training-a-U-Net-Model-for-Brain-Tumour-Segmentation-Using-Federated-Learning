{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model\n",
    "\n",
    "In this tutorial we will use TensorFlow to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import platform\n",
    "import os\n",
    "\n",
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"{}\".format(platform.platform()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biomedical Image Segmentation with U-Net\n",
    "\n",
    "In this code example, we apply the U-Net architecture to segment brain tumors from raw MRI scans as shown below. With relatively little data we are able to train a U-Net model to accurately predict where tumors exist. \n",
    "\n",
    "The Dice coefficient (the standard metric for the BraTS dataset used in the study) for our model is about 0.82-0.88.  Menze et al. [reported](http://ieeexplore.ieee.org/document/6975210/) that expert neuroradiologists manually segmented these tumors with a cross-rater Dice score of 0.75-0.85, meaning that the model’s predictions are on par with what expert physicians have made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/figure1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since its introduction two years ago, the [U-Net](https://arxiv.org/pdf/1505.04597.pdf0) architecture has been used to create deep learning models for segmenting [nerves](https://github.com/jocicmarko/ultrasound-nerve-segmentation) in ultrasound images, [lungs](https://www.kaggle.com/c/data-science-bowl-2017#tutorial) in CT scans, and even [interference](https://github.com/jakeret/tf_unet) in radio telescopes.\n",
    "\n",
    "## What is U-Net?\n",
    "U-Net is designed like an [auto-encoder](https://en.wikipedia.org/wiki/Autoencoder). It has an encoding path (“contracting”) paired with a decoding path (“expanding”) which gives it the “U” shape.  However, in contrast to the autoencoder, U-Net predicts a pixelwise segmentation map of the input image rather than classifying the input image as a whole. For each pixel in the original image, it asks the question: “To which class does this pixel belong?” This flexibility allows U-Net to predict different parts of the tumor simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/unet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module loads the data generator from `dataloader.py`, creates a TensorFlow/Keras model from `model.py`, trains the model on the data, and then saves the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Version Check\n",
    "\n",
    "Check to see what version of TensorFlow is installed and if it has [Intel DNNL optimizations](https://software.intel.com/content/www/us/en/develop/articles/intel-optimization-for-tensorflow-installation-guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_intel_tensorflow():\n",
    "    \"\"\"\n",
    "    Check if Intel version of TensorFlow is installed\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    print(\"We are using Tensorflow version {}\".format(tf.__version__))\n",
    "           \n",
    "    major_version = int(tf.__version__.split(\".\")[0])\n",
    "    if major_version >= 2:\n",
    "       from tensorflow.python import _pywrap_util_port\n",
    "       print(\"Intel-optimizations (DNNL) enabled:\", _pywrap_util_port.IsMklEnabled())\n",
    "    else:\n",
    "       print(\"Intel-optimizations (DNNL) enabled:\", tf.pywrap_tensorflow.IsMklEnabled()) \n",
    "\n",
    "test_intel_tensorflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bulk of the training section can be broken down in 4 simple steps:\n",
    "1. Load the training data\n",
    "1. Define the model\n",
    "3. Train the model on the data\n",
    "4. Evaluate the best model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : Loading the BraTS data set from the tf.data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/data/medical_decathlon/Task01_BrainTumour/\"\n",
    "\n",
    "crop_dim=128  # Original resolution (240)\n",
    "batch_size = 128\n",
    "seed=816\n",
    "train_test_split=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import DatasetGenerator, get_decathlon_filelist\n",
    "\n",
    "trainFiles, validateFiles, testFiles = get_decathlon_filelist(data_path=data_path, seed=seed, split=train_test_split)\n",
    "\n",
    "# TODO: Fill in the missing parameters (...) for the data generator \n",
    "\n",
    "ds_train = DatasetGenerator(...)\n",
    "\n",
    "ds_validation = DatasetGenerator(...)\n",
    "\n",
    "ds_test = DatasetGenerator(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some samples of the dataset\n",
    "\n",
    "We can use the DatasetGenerator's plot_samples function to plot a few samples of the dataset. Note that with `augment` set to True, we have randomly cropped, flipped, and rotated the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_train.plot_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_validation.plot_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import unet\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"Creating and compiling model ...\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "unet_model = unet(fms=16, learning_rate=1e-4, use_dropout=False, use_upsampling=False)\n",
    "\n",
    "model = unet_model.create_model(\n",
    "        ds_train.get_input_shape(), \n",
    "        ds_train.get_output_shape())\n",
    "\n",
    "model_filename, model_callbacks = unet_model.get_callbacks()\n",
    "\n",
    "# # If there is a current saved file, then load weights and start from there.\n",
    "# saved_model = os.path.join(args.output_path, args.inference_filename)\n",
    "# if os.path.isfile(saved_model):\n",
    "#     model.load_weights(saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet below draws the model using Keras' built-in `plot_model`. Compare with the implementation of `model.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "plot_model(model,\n",
    "           to_file='images/model.png',\n",
    "           show_shapes=True,\n",
    "           show_layer_names=True,\n",
    "           rankdir='TB'\n",
    "            )\n",
    "Image('images/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Train the model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Training started at {}\".format(start_time))\n",
    "\n",
    "n_epoch = 2  # Train for this many epochs\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "              epochs=n_epoch,\n",
    "              validation_data=ds_validation,\n",
    "              verbose=1,\n",
    "              callbacks=model_callbacks)\n",
    "\n",
    "print(\"Total time elapsed for training = {} seconds\".format(datetime.datetime.now() - start_time))\n",
    "print(\"Training finished at {}\".format(datetime.datetime.now()))\n",
    "    \n",
    "# Append training log\n",
    "# with open(\"training.log\",\"a+\") as fp:\n",
    "#     fp.write(\"{}: {}\\n\".format(datetime.datetime.now(),\n",
    "#                              history.history[\"val_dice_coef\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Evaluate the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 30)\n",
    "print(\"Loading the best trained model ...\")\n",
    "print(\"-\" * 30)\n",
    "unet_model.evaluate_model(model_filename, ds_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End: In this tutorial, you have learnt:\n",
    "* What is the U-Net model\n",
    "* Comparing training times - Tensorflow DNNL vs Tensorflow (stock)\n",
    "* How to tweak a series of environment variables to get better performance out of DNNL\n",
    "* How to tweak a series of Tensorflow-related and neural-network specific parameters for better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. SPDX-License-Identifier: EPL-2.0*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (c) 2019-2020 Intel Corporation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
